# Data description

## TDIDF
1. **TFIDF_1.sav:** - text_depositions uncleaned \#7995
  * Basic porter stemmer with english stopwords and normalized features.
  * Tokenized using nltk.word_tokenize.

<!-- 2. **TFIDF_2.sav:** Ignoring tokens that are smaller than 4 characters in length. -->

## Kmeans

1. Kmeans_1_1.sav - 10 clusters


## Tokens

1. **tokens_1.sav**
  * Unique Tokens in every files stored as a dict in a class.
   
